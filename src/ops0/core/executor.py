import time
from typing import Dict, Any, Optional
from src.ops0.core.graph import PipelineGraph



class PipelineExecutor:
    """
    Local pipeline execution engine.

    Orchestrates step execution based on dependency graph analysis.
    """

    def __init__(self, pipeline: PipelineGraph):
        self.pipeline = pipeline
        self.results = {}
        self.execution_times = {}

    def execute(self, mode: str = "local") -> Dict[str, Any]:
        """
        Execute the pipeline in the specified mode.

        Args:
            mode: Execution mode ("local" or "distributed")

        Returns:
            Dict of step results
        """
        if mode == "local":
            return self._execute_local()
        elif mode == "distributed":
            return self._execute_distributed()
        else:
            raise ValueError(f"Unknown execution mode: {mode}")

    def _execute_local(self) -> Dict[str, Any]:
        """Execute pipeline locally with progress tracking"""
        print(f"\nğŸš€ Executing pipeline: {self.pipeline.name}")
        print("=" * 50)

        execution_order = self.pipeline.build_execution_order()
        total_steps = len(self.pipeline.steps)
        completed_steps = 0

        for level, parallel_steps in enumerate(execution_order):
            print(f"\nğŸ“‹ Level {level + 1}: {len(parallel_steps)} step(s)")

            # Execute steps in parallel (simplified - could use threading)
            for step_name in parallel_steps:
                start_time = time.time()

                step_node = self.pipeline.steps[step_name]
                print(f"  âš¡ Executing: {step_name}")

                try:
                    # Execute the step function
                    result = step_node.func()

                    # Store result
                    step_node.result = result
                    step_node.executed = True
                    self.results[step_name] = result

                    execution_time = time.time() - start_time
                    self.execution_times[step_name] = execution_time

                    completed_steps += 1
                    progress = (completed_steps / total_steps) * 100

                    print(f"  âœ… {step_name} completed in {execution_time:.2f}s ({progress:.0f}%)")

                except Exception as e:
                    print(f"  âŒ {step_name} failed: {str(e)}")
                    raise

        total_time = sum(self.execution_times.values())
        print(f"\nğŸ‰ Pipeline completed in {total_time:.2f}s")
        print(f"ğŸ“Š Executed {total_steps} steps across {len(execution_order)} levels")

        return self.results

    def _execute_distributed(self) -> Dict[str, Any]:
        """Execute pipeline in distributed mode (placeholder for Phase 2)"""
        print("ğŸŒ Distributed execution coming in Phase 2!")
        return self._execute_local()


def run(mode: str = "local", pipeline_name: Optional[str] = None) -> Dict[str, Any]:
    """
    Run the current or specified pipeline.

    Args:
        mode: Execution mode ("local" or "distributed")
        pipeline_name: Optional pipeline name

    Returns:
        Pipeline execution results
    """
    current_pipeline = PipelineGraph.get_current()

    if not current_pipeline:
        raise ValueError("No active pipeline found. Use @ops0.pipeline or with ops0.pipeline():")

    executor = PipelineExecutor(current_pipeline)
    return executor.execute(mode)


def deploy(name: Optional[str] = None, env: str = "production") -> Dict[str, str]:
    """
    Deploy pipeline to production with automatic containerization.

    Args:
        name: Pipeline name
        env: Environment ("staging" or "production")

    Returns:
        Deployment info
    """
    current_pipeline = PipelineGraph.get_current()
    pipeline_name = name or (current_pipeline.name if current_pipeline else "unnamed")

    print(f"\nğŸš€ Deploying pipeline: {pipeline_name}")
    print(f"ğŸŒ Environment: {env}")
    print("=" * 50)

    if current_pipeline:
        # Auto-containerization
        print("ğŸ³ Auto-containerizing pipeline steps...")
        from src.ops0.runtime.containers import container_orchestrator

        # Enable container building for deployment
        import os
        os.environ["OPS0_BUILD_CONTAINERS"] = "true"

        try:
            specs = container_orchestrator.containerize_pipeline(current_pipeline)
            print(f"âœ… Containerized {len(specs)} steps")

            # Generate deployment manifest
            manifest = container_orchestrator.get_container_manifest()
            print(f"ğŸ“‹ Generated deployment manifest")

        except Exception as e:
            print(f"âŒ Containerization failed: {str(e)}")
            print("ğŸ”„ Falling back to local deployment...")

    print("âš¡ Building containers...")
    time.sleep(1)  # Simulate build time
    print("â˜ï¸  Pushing to registry...")
    time.sleep(1)  # Simulate push time
    print("ğŸ”„ Updating orchestrator...")
    time.sleep(0.5)

    url = f"https://{pipeline_name}.ops0.xyz"
    print(f"âœ… Pipeline deployed successfully!")
    print(f"ğŸ”— URL: {url}")
    print(f"ğŸ³ Containers: {len(current_pipeline.steps) if current_pipeline else 1}")

    return {
        "status": "deployed",
        "url": url,
        "environment": env,
        "pipeline": pipeline_name,
        "containers": len(current_pipeline.steps) if current_pipeline else 1
    }
